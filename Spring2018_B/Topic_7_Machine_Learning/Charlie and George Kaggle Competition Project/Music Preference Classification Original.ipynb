{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.svm.libsvm import predict_proba\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members = pd.read_csv('members.csv')\n",
    "songs = pd.read_csv('songs.csv')\n",
    "song_extra = pd.read_csv('song_extra_info.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test_sub = pd.read_csv('test.csv')\n",
    "\n",
    "df = pd.merge(train, songs[['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']], \n",
    "              on='song_id', how='left')\n",
    "\n",
    "test_sub = pd.merge(test_sub, songs[['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']], \n",
    "              on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting registration/expiration year, month, and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert registration init_time to understandable values (year, month, date)\n",
    "members['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['registration_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['registration_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "# Convert expiration init_time to understandable values (year, month, date)\n",
    "members['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['expiration_date'] = members['expiration_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "members = members.drop(['registration_init_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging member into the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, members, on='msno', how='left')\n",
    "test_sub = pd.merge(test_sub, members, on='msno', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the song release year from isrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "song_extra['song_year'] = song_extra['isrc'].apply(isrc_to_year)\n",
    "song_extra.drop(['isrc', 'name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging song_extra into the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, song_extra, on='song_id', how='left')\n",
    "test_sub = pd.merge(test_sub, song_extra, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute values into testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create imputer object\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'median')\n",
    "# impute for Ozone\n",
    "test_sub['song_length'] = imp.fit_transform(test_sub[['song_length']])\n",
    "test_sub['language'] = imp.fit_transform(test_sub[['language']])\n",
    "test_sub['song_year'] = imp.fit_transform(test_sub[['song_year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_cat = ['msno', 'song_id', 'source_system_tab', 'source_screen_name',\n",
    "       'source_type', 'artist_name', 'genre_ids', 'language', 'city', 'gender',\n",
    "       'registered_via']\n",
    "for col in to_cat:\n",
    "    df[col] = df[col].astype('category')\n",
    "    test_sub[col] = test_sub[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "#Create a column for is_featured\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "df['is_featured'] = df['artist_name'].apply(is_featured).astype(np.int8)\n",
    "test_sub['is_featured'] = test_sub['artist_name'].apply(is_featured).astype(np.int8)\n",
    "\n",
    "\n",
    "#Artist count\n",
    "def artist_count(x):\n",
    "    if x == 'no_artist':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "df['artist_count'] = df['artist_name'].apply(artist_count).astype(np.int8)\n",
    "test_sub['artist_count'] = test_sub['artist_name'].apply(artist_count).astype(np.int8)\n",
    "\n",
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in df['song_id'].value_counts().iteritems()}\n",
    "_dict_count_song_played_test = {k: v for k, v in test_sub['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_song_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "df['count_song_played'] = df['song_id'].apply(count_song_played).astype(np.int64)\n",
    "test_sub['count_song_played'] = test_sub['song_id'].apply(count_song_played).astype(np.int64)\n",
    "\n",
    "# number of times the artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in df['artist_name'].value_counts().iteritems()}\n",
    "_dict_count_artist_played_test = {k: v for k, v in test_sub['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_artist_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "df['count_artist_played'] = df['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "test_sub['count_artist_played'] = test_sub['artist_name'].apply(count_artist_played).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popping Target and dropping NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = test_sub.pop('id')\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3814669 entries, 1 to 7377413\n",
      "Data columns (total 25 columns):\n",
      "msno                   category\n",
      "song_id                category\n",
      "source_system_tab      category\n",
      "source_screen_name     category\n",
      "source_type            category\n",
      "target                 int64\n",
      "artist_name            category\n",
      "genre_ids              category\n",
      "song_length            float64\n",
      "language               category\n",
      "city                   category\n",
      "bd                     int64\n",
      "gender                 category\n",
      "registered_via         category\n",
      "expiration_date        int64\n",
      "registration_year      int64\n",
      "registration_month     int64\n",
      "registration_date      int64\n",
      "expiration_year        int64\n",
      "expiration_month       int64\n",
      "song_year              float64\n",
      "is_featured            int8\n",
      "artist_count           int8\n",
      "count_song_played      int64\n",
      "count_artist_played    int64\n",
      "dtypes: category(11), float64(2), int64(10), int8(2)\n",
      "memory usage: 470.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Feature Importance and OOB Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_df = df.sample(math.floor(len(df)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'female'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ad0e4fdedcb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \"\"\"\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'female'"
     ]
    }
   ],
   "source": [
    "model_df['RANDOM'] = np.random.rand(len(model_df))*100\n",
    "\n",
    "# model\n",
    "forest = RandomForestClassifier(oob_score = True, n_estimators = 500, n_jobs = 2)\n",
    "\n",
    "# train\n",
    "forest.fit(model_df.drop('target', 1), model_df['target'])\n",
    "\n",
    "# feature importances\n",
    "print(pd.DataFrame({'Importance': forest.feature_importances_}, \n",
    "                   index = model_df.drop('target', 1).columns).sort_values('Importance', \n",
    "                                                                             ascending = False))\n",
    "\n",
    "# Random column is no longer necessary\n",
    "model_df.drop('RANDOM', 1, inplace = True)\n",
    "\n",
    "# Out of bag score\n",
    "forest.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(model_df, test_size = 0.1)\n",
    "\n",
    "# train sets\n",
    "train_x = train.drop('target', 1)\n",
    "train_y = train['target'].values\n",
    "\n",
    "# test sets\n",
    "test_x = test.drop('target', 1)\n",
    "test_y = test['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "boost = GradientBoostingClassifier(n_estimators = 70)\n",
    "\n",
    "# train\n",
    "boost.fit(train_x, train_y)\n",
    "\n",
    "# predict\n",
    "boost_predictions = boost.predict(test_x)\n",
    "\n",
    "# AUC score\n",
    "print(roc_auc_score(test_y, boost_predictions), '\\n')\n",
    "\n",
    "# feature importances\n",
    "print(pd.DataFrame({'Importance': boost.feature_importances_}, \n",
    "                   index = train_x.columns).sort_values('Importance', ascending = False))\n",
    "\n",
    "# confusion matrix\n",
    "pd.crosstab(test_y, boost_predictions, rownames=['Actual'], colnames = ['Predicted:'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_x, label = train_y)\n",
    "\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_train,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "lgbm_pred = gbm.predict(test_x, num_iteration=gbm.best_iteration)\n",
    "\n",
    "roc_auc_score(test_y, lgbm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models based on gender/language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgbm_train(data, col_name, attribute):\n",
    "    data = data.loc[data[col_name] == attribute]\n",
    "    train_x_g = data.drop(['target', col_name], 1)\n",
    "    train_y_g = data['target'].values\n",
    "    \n",
    "    lgb_train_g = lgb.Dataset(train_x_g, label = train_y_g)\n",
    "\n",
    "    params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'boosting': 'dart',\n",
    "            'learning_rate': 0.3 ,\n",
    "            'verbose': 0,\n",
    "            'num_leaves': 108,\n",
    "            'bagging_fraction': 0.95,\n",
    "            'bagging_freq': 1,\n",
    "            'bagging_seed': 1,\n",
    "            'feature_fraction': 0.9,\n",
    "            'feature_fraction_seed': 1,\n",
    "            'max_bin': 256,\n",
    "            'max_depth': 10,\n",
    "            'num_rounds': 200,\n",
    "            'metric' : 'auc'}\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train_g,\n",
    "                    num_boost_round=100,\n",
    "                    valid_sets=lgb_train_g,\n",
    "                    early_stopping_rounds=5)\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting models in hash table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_models = {}\n",
    "for gen in model_df['gender'].unique():\n",
    "    gender_models[gen] = lgbm_train(df, gender, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.738313\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.756061\n",
      "[3]\ttraining's auc: 0.765407\n",
      "[4]\ttraining's auc: 0.770733\n",
      "[5]\ttraining's auc: 0.77689\n",
      "[6]\ttraining's auc: 0.780774\n",
      "[7]\ttraining's auc: 0.786566\n",
      "[8]\ttraining's auc: 0.787278\n",
      "[9]\ttraining's auc: 0.79022\n",
      "[10]\ttraining's auc: 0.791927\n",
      "[11]\ttraining's auc: 0.793897\n",
      "[12]\ttraining's auc: 0.793838\n",
      "[13]\ttraining's auc: 0.79574\n",
      "[14]\ttraining's auc: 0.797616\n",
      "[15]\ttraining's auc: 0.799134\n",
      "[16]\ttraining's auc: 0.800643\n",
      "[17]\ttraining's auc: 0.802233\n",
      "[18]\ttraining's auc: 0.803548\n",
      "[19]\ttraining's auc: 0.804616\n",
      "[20]\ttraining's auc: 0.805808\n",
      "[21]\ttraining's auc: 0.806202\n",
      "[22]\ttraining's auc: 0.807209\n",
      "[23]\ttraining's auc: 0.807849\n",
      "[24]\ttraining's auc: 0.808868\n",
      "[25]\ttraining's auc: 0.810006\n",
      "[26]\ttraining's auc: 0.811087\n",
      "[27]\ttraining's auc: 0.812062\n",
      "[28]\ttraining's auc: 0.81177\n",
      "[29]\ttraining's auc: 0.812615\n",
      "[30]\ttraining's auc: 0.813381\n",
      "[31]\ttraining's auc: 0.81335\n",
      "[32]\ttraining's auc: 0.814044\n",
      "[33]\ttraining's auc: 0.814778\n",
      "[34]\ttraining's auc: 0.816248\n",
      "[35]\ttraining's auc: 0.815989\n",
      "[36]\ttraining's auc: 0.816076\n",
      "[37]\ttraining's auc: 0.817033\n",
      "[38]\ttraining's auc: 0.81766\n",
      "[39]\ttraining's auc: 0.818788\n",
      "[40]\ttraining's auc: 0.820057\n",
      "[41]\ttraining's auc: 0.819831\n",
      "[42]\ttraining's auc: 0.820099\n",
      "[43]\ttraining's auc: 0.819947\n",
      "[44]\ttraining's auc: 0.821274\n",
      "[45]\ttraining's auc: 0.821845\n",
      "[46]\ttraining's auc: 0.822635\n",
      "[47]\ttraining's auc: 0.823786\n",
      "[48]\ttraining's auc: 0.824027\n",
      "[49]\ttraining's auc: 0.823825\n",
      "[50]\ttraining's auc: 0.823506\n",
      "[51]\ttraining's auc: 0.823718\n",
      "[52]\ttraining's auc: 0.824364\n",
      "[53]\ttraining's auc: 0.82428\n",
      "[54]\ttraining's auc: 0.825382\n",
      "[55]\ttraining's auc: 0.826014\n",
      "[56]\ttraining's auc: 0.825749\n",
      "[57]\ttraining's auc: 0.827091\n",
      "[58]\ttraining's auc: 0.827809\n",
      "[59]\ttraining's auc: 0.82786\n",
      "[60]\ttraining's auc: 0.828604\n",
      "[61]\ttraining's auc: 0.829215\n",
      "[62]\ttraining's auc: 0.829868\n",
      "[63]\ttraining's auc: 0.830656\n",
      "[64]\ttraining's auc: 0.831179\n",
      "[65]\ttraining's auc: 0.830905\n",
      "[66]\ttraining's auc: 0.831148\n",
      "[67]\ttraining's auc: 0.831433\n",
      "[68]\ttraining's auc: 0.831846\n",
      "[69]\ttraining's auc: 0.831611\n",
      "[70]\ttraining's auc: 0.831424\n",
      "[71]\ttraining's auc: 0.831435\n",
      "[72]\ttraining's auc: 0.832505\n",
      "[73]\ttraining's auc: 0.833339\n",
      "[74]\ttraining's auc: 0.83323\n",
      "[75]\ttraining's auc: 0.833487\n",
      "[76]\ttraining's auc: 0.83363\n",
      "[77]\ttraining's auc: 0.833465\n",
      "[78]\ttraining's auc: 0.833666\n",
      "[79]\ttraining's auc: 0.834316\n",
      "[80]\ttraining's auc: 0.834936\n",
      "[81]\ttraining's auc: 0.834797\n",
      "[82]\ttraining's auc: 0.835225\n",
      "[83]\ttraining's auc: 0.835084\n",
      "[84]\ttraining's auc: 0.834834\n",
      "[85]\ttraining's auc: 0.834729\n",
      "[86]\ttraining's auc: 0.835235\n",
      "[87]\ttraining's auc: 0.835571\n",
      "[88]\ttraining's auc: 0.835434\n",
      "[89]\ttraining's auc: 0.835589\n",
      "[90]\ttraining's auc: 0.835427\n",
      "[91]\ttraining's auc: 0.835941\n",
      "[92]\ttraining's auc: 0.836201\n",
      "[93]\ttraining's auc: 0.836954\n",
      "[94]\ttraining's auc: 0.836741\n",
      "[95]\ttraining's auc: 0.836714\n",
      "[96]\ttraining's auc: 0.836657\n",
      "[97]\ttraining's auc: 0.837094\n",
      "[98]\ttraining's auc: 0.837057\n",
      "[99]\ttraining's auc: 0.837719\n",
      "[100]\ttraining's auc: 0.837904\n",
      "[101]\ttraining's auc: 0.838053\n",
      "[102]\ttraining's auc: 0.837839\n",
      "[103]\ttraining's auc: 0.837857\n",
      "[104]\ttraining's auc: 0.838233\n",
      "[105]\ttraining's auc: 0.838466\n",
      "[106]\ttraining's auc: 0.838331\n",
      "[107]\ttraining's auc: 0.83831\n",
      "[108]\ttraining's auc: 0.83814\n",
      "[109]\ttraining's auc: 0.838177\n",
      "[110]\ttraining's auc: 0.838072\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's auc: 0.838466\n",
      "[1]\ttraining's auc: 0.717832\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.730322\n",
      "[3]\ttraining's auc: 0.739569\n",
      "[4]\ttraining's auc: 0.746145\n",
      "[5]\ttraining's auc: 0.752441\n",
      "[6]\ttraining's auc: 0.757147\n",
      "[7]\ttraining's auc: 0.761424\n",
      "[8]\ttraining's auc: 0.761365\n",
      "[9]\ttraining's auc: 0.763946\n",
      "[10]\ttraining's auc: 0.765628\n",
      "[11]\ttraining's auc: 0.767601\n",
      "[12]\ttraining's auc: 0.767591\n",
      "[13]\ttraining's auc: 0.769892\n",
      "[14]\ttraining's auc: 0.772596\n",
      "[15]\ttraining's auc: 0.774451\n",
      "[16]\ttraining's auc: 0.775945\n",
      "[17]\ttraining's auc: 0.777258\n",
      "[18]\ttraining's auc: 0.77838\n",
      "[19]\ttraining's auc: 0.77998\n",
      "[20]\ttraining's auc: 0.780666\n",
      "[21]\ttraining's auc: 0.781107\n",
      "[22]\ttraining's auc: 0.782163\n",
      "[23]\ttraining's auc: 0.782816\n",
      "[24]\ttraining's auc: 0.783754\n",
      "[25]\ttraining's auc: 0.784664\n",
      "[26]\ttraining's auc: 0.785485\n",
      "[27]\ttraining's auc: 0.786354\n",
      "[28]\ttraining's auc: 0.786123\n",
      "[29]\ttraining's auc: 0.786984\n",
      "[30]\ttraining's auc: 0.787777\n",
      "[31]\ttraining's auc: 0.787866\n",
      "[32]\ttraining's auc: 0.788504\n",
      "[33]\ttraining's auc: 0.789297\n",
      "[34]\ttraining's auc: 0.789988\n",
      "[35]\ttraining's auc: 0.789749\n",
      "[36]\ttraining's auc: 0.789705\n",
      "[37]\ttraining's auc: 0.791613\n",
      "[38]\ttraining's auc: 0.792634\n",
      "[39]\ttraining's auc: 0.793153\n",
      "[40]\ttraining's auc: 0.794088\n",
      "[41]\ttraining's auc: 0.793759\n",
      "[42]\ttraining's auc: 0.794154\n",
      "[43]\ttraining's auc: 0.793905\n",
      "[44]\ttraining's auc: 0.794319\n",
      "[45]\ttraining's auc: 0.794676\n",
      "[46]\ttraining's auc: 0.795486\n",
      "[47]\ttraining's auc: 0.797111\n",
      "[48]\ttraining's auc: 0.796934\n",
      "[49]\ttraining's auc: 0.796708\n",
      "[50]\ttraining's auc: 0.796571\n",
      "[51]\ttraining's auc: 0.797551\n",
      "[52]\ttraining's auc: 0.798383\n",
      "[53]\ttraining's auc: 0.798407\n",
      "[54]\ttraining's auc: 0.799133\n",
      "[55]\ttraining's auc: 0.799786\n",
      "[56]\ttraining's auc: 0.799604\n",
      "[57]\ttraining's auc: 0.800123\n",
      "[58]\ttraining's auc: 0.800737\n",
      "[59]\ttraining's auc: 0.800807\n",
      "[60]\ttraining's auc: 0.801637\n",
      "[61]\ttraining's auc: 0.802278\n",
      "[62]\ttraining's auc: 0.802809\n",
      "[63]\ttraining's auc: 0.803506\n",
      "[64]\ttraining's auc: 0.803801\n",
      "[65]\ttraining's auc: 0.803593\n",
      "[66]\ttraining's auc: 0.803558\n",
      "[67]\ttraining's auc: 0.803852\n",
      "[68]\ttraining's auc: 0.804272\n",
      "[69]\ttraining's auc: 0.804097\n",
      "[70]\ttraining's auc: 0.80396\n",
      "[71]\ttraining's auc: 0.80401\n",
      "[72]\ttraining's auc: 0.804759\n",
      "[73]\ttraining's auc: 0.805091\n",
      "[74]\ttraining's auc: 0.804911\n",
      "[75]\ttraining's auc: 0.805493\n",
      "[76]\ttraining's auc: 0.805505\n",
      "[77]\ttraining's auc: 0.805367\n",
      "[78]\ttraining's auc: 0.805432\n",
      "[79]\ttraining's auc: 0.806021\n",
      "[80]\ttraining's auc: 0.806662\n",
      "[81]\ttraining's auc: 0.806576\n",
      "[82]\ttraining's auc: 0.807199\n",
      "[83]\ttraining's auc: 0.807095\n",
      "[84]\ttraining's auc: 0.806953\n",
      "[85]\ttraining's auc: 0.806764\n",
      "[86]\ttraining's auc: 0.807185\n",
      "[87]\ttraining's auc: 0.807207\n",
      "[88]\ttraining's auc: 0.807127\n",
      "[89]\ttraining's auc: 0.807268\n",
      "[90]\ttraining's auc: 0.80715\n",
      "[91]\ttraining's auc: 0.807607\n",
      "[92]\ttraining's auc: 0.808213\n",
      "[93]\ttraining's auc: 0.808654\n",
      "[94]\ttraining's auc: 0.808499\n",
      "[95]\ttraining's auc: 0.808479\n",
      "[96]\ttraining's auc: 0.808387\n",
      "[97]\ttraining's auc: 0.809066\n",
      "[98]\ttraining's auc: 0.809052\n",
      "[99]\ttraining's auc: 0.80944\n",
      "[100]\ttraining's auc: 0.809455\n",
      "[101]\ttraining's auc: 0.809651\n",
      "[102]\ttraining's auc: 0.809446\n",
      "[103]\ttraining's auc: 0.809424\n",
      "[104]\ttraining's auc: 0.809955\n",
      "[105]\ttraining's auc: 0.810126\n",
      "[106]\ttraining's auc: 0.809963\n",
      "[107]\ttraining's auc: 0.809908\n",
      "[108]\ttraining's auc: 0.809872\n",
      "[109]\ttraining's auc: 0.809789\n",
      "[110]\ttraining's auc: 0.809746\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's auc: 0.810126\n",
      "[1]\ttraining's auc: 0.755267\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.770022\n",
      "[3]\ttraining's auc: 0.783829\n",
      "[4]\ttraining's auc: 0.790506\n",
      "[5]\ttraining's auc: 0.799633\n",
      "[6]\ttraining's auc: 0.803821\n",
      "[7]\ttraining's auc: 0.808956\n",
      "[8]\ttraining's auc: 0.809502\n",
      "[9]\ttraining's auc: 0.813604\n",
      "[10]\ttraining's auc: 0.816933\n",
      "[11]\ttraining's auc: 0.819132\n",
      "[12]\ttraining's auc: 0.81928\n",
      "[13]\ttraining's auc: 0.820972\n",
      "[14]\ttraining's auc: 0.822826\n",
      "[15]\ttraining's auc: 0.825257\n",
      "[16]\ttraining's auc: 0.826759\n",
      "[17]\ttraining's auc: 0.828088\n",
      "[18]\ttraining's auc: 0.830377\n",
      "[19]\ttraining's auc: 0.831593\n",
      "[20]\ttraining's auc: 0.833238\n",
      "[21]\ttraining's auc: 0.833474\n",
      "[22]\ttraining's auc: 0.834537\n",
      "[23]\ttraining's auc: 0.835432\n",
      "[24]\ttraining's auc: 0.836657\n",
      "[25]\ttraining's auc: 0.837777\n",
      "[26]\ttraining's auc: 0.838944\n",
      "[27]\ttraining's auc: 0.839863\n",
      "[28]\ttraining's auc: 0.839775\n",
      "[29]\ttraining's auc: 0.840678\n",
      "[30]\ttraining's auc: 0.84156\n",
      "[31]\ttraining's auc: 0.841687\n",
      "[32]\ttraining's auc: 0.842578\n",
      "[33]\ttraining's auc: 0.843429\n",
      "[34]\ttraining's auc: 0.844409\n",
      "[35]\ttraining's auc: 0.844194\n",
      "[36]\ttraining's auc: 0.844308\n",
      "[37]\ttraining's auc: 0.845562\n",
      "[38]\ttraining's auc: 0.846804\n",
      "[39]\ttraining's auc: 0.84748\n",
      "[40]\ttraining's auc: 0.848668\n",
      "[41]\ttraining's auc: 0.848463\n",
      "[42]\ttraining's auc: 0.84887\n",
      "[43]\ttraining's auc: 0.848597\n",
      "[44]\ttraining's auc: 0.849574\n",
      "[45]\ttraining's auc: 0.850199\n",
      "[46]\ttraining's auc: 0.850916\n",
      "[47]\ttraining's auc: 0.852199\n",
      "[48]\ttraining's auc: 0.852558\n",
      "[49]\ttraining's auc: 0.852286\n",
      "[50]\ttraining's auc: 0.852124\n",
      "[51]\ttraining's auc: 0.853194\n",
      "[52]\ttraining's auc: 0.854254\n",
      "[53]\ttraining's auc: 0.85418\n",
      "[54]\ttraining's auc: 0.85493\n",
      "[55]\ttraining's auc: 0.855805\n",
      "[56]\ttraining's auc: 0.855525\n",
      "[57]\ttraining's auc: 0.856024\n",
      "[58]\ttraining's auc: 0.85652\n",
      "[59]\ttraining's auc: 0.856663\n",
      "[60]\ttraining's auc: 0.857435\n",
      "[61]\ttraining's auc: 0.857815\n",
      "[62]\ttraining's auc: 0.858582\n",
      "[63]\ttraining's auc: 0.859148\n",
      "[64]\ttraining's auc: 0.859561\n",
      "[65]\ttraining's auc: 0.859351\n",
      "[66]\ttraining's auc: 0.860048\n",
      "[67]\ttraining's auc: 0.860457\n",
      "[68]\ttraining's auc: 0.861307\n",
      "[69]\ttraining's auc: 0.861059\n",
      "[70]\ttraining's auc: 0.860914\n",
      "[71]\ttraining's auc: 0.861026\n",
      "[72]\ttraining's auc: 0.861423\n",
      "[73]\ttraining's auc: 0.862224\n",
      "[74]\ttraining's auc: 0.86199\n",
      "[75]\ttraining's auc: 0.862641\n",
      "[76]\ttraining's auc: 0.862716\n",
      "[77]\ttraining's auc: 0.862598\n",
      "[78]\ttraining's auc: 0.862927\n",
      "[79]\ttraining's auc: 0.863545\n",
      "[80]\ttraining's auc: 0.863797\n",
      "[81]\ttraining's auc: 0.863742\n",
      "[82]\ttraining's auc: 0.864104\n",
      "[83]\ttraining's auc: 0.863963\n",
      "[84]\ttraining's auc: 0.863823\n",
      "[85]\ttraining's auc: 0.863774\n",
      "[86]\ttraining's auc: 0.864652\n",
      "[87]\ttraining's auc: 0.86502\n",
      "[88]\ttraining's auc: 0.864849\n",
      "[89]\ttraining's auc: 0.865046\n",
      "[90]\ttraining's auc: 0.86483\n",
      "[91]\ttraining's auc: 0.865265\n",
      "[92]\ttraining's auc: 0.865434\n",
      "[93]\ttraining's auc: 0.866079\n",
      "[94]\ttraining's auc: 0.865915\n",
      "[95]\ttraining's auc: 0.86586\n",
      "[96]\ttraining's auc: 0.865715\n",
      "[97]\ttraining's auc: 0.866266\n",
      "[98]\ttraining's auc: 0.866188\n",
      "[99]\ttraining's auc: 0.866443\n",
      "[100]\ttraining's auc: 0.867068\n",
      "[101]\ttraining's auc: 0.86725\n",
      "[102]\ttraining's auc: 0.867088\n",
      "[103]\ttraining's auc: 0.86707\n",
      "[104]\ttraining's auc: 0.867271\n",
      "[105]\ttraining's auc: 0.867475\n",
      "[106]\ttraining's auc: 0.867369\n",
      "[107]\ttraining's auc: 0.867276\n",
      "[108]\ttraining's auc: 0.867423\n",
      "[109]\ttraining's auc: 0.867405\n",
      "[110]\ttraining's auc: 0.867256\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's auc: 0.867475\n",
      "[1]\ttraining's auc: 0.777126\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.793233\n",
      "[3]\ttraining's auc: 0.808793\n",
      "[4]\ttraining's auc: 0.815691\n",
      "[5]\ttraining's auc: 0.823526\n",
      "[6]\ttraining's auc: 0.829208\n",
      "[7]\ttraining's auc: 0.837641\n",
      "[8]\ttraining's auc: 0.838029\n",
      "[9]\ttraining's auc: 0.841469\n",
      "[10]\ttraining's auc: 0.84537\n",
      "[11]\ttraining's auc: 0.848262\n",
      "[12]\ttraining's auc: 0.848107\n",
      "[13]\ttraining's auc: 0.850252\n",
      "[14]\ttraining's auc: 0.852074\n",
      "[15]\ttraining's auc: 0.854309\n",
      "[16]\ttraining's auc: 0.856034\n",
      "[17]\ttraining's auc: 0.858168\n",
      "[18]\ttraining's auc: 0.860755\n",
      "[19]\ttraining's auc: 0.862277\n",
      "[20]\ttraining's auc: 0.864099\n",
      "[21]\ttraining's auc: 0.864415\n",
      "[22]\ttraining's auc: 0.865572\n",
      "[23]\ttraining's auc: 0.867484\n",
      "[24]\ttraining's auc: 0.868869\n",
      "[25]\ttraining's auc: 0.870137\n",
      "[26]\ttraining's auc: 0.871375\n",
      "[27]\ttraining's auc: 0.872248\n",
      "[28]\ttraining's auc: 0.872154\n",
      "[29]\ttraining's auc: 0.87318\n",
      "[30]\ttraining's auc: 0.874255\n",
      "[31]\ttraining's auc: 0.874939\n",
      "[32]\ttraining's auc: 0.875828\n",
      "[33]\ttraining's auc: 0.876939\n",
      "[34]\ttraining's auc: 0.877834\n",
      "[35]\ttraining's auc: 0.87744\n",
      "[36]\ttraining's auc: 0.877424\n",
      "[37]\ttraining's auc: 0.878278\n",
      "[38]\ttraining's auc: 0.87909\n",
      "[39]\ttraining's auc: 0.88048\n",
      "[40]\ttraining's auc: 0.881701\n",
      "[41]\ttraining's auc: 0.881583\n",
      "[42]\ttraining's auc: 0.88216\n",
      "[43]\ttraining's auc: 0.881817\n",
      "[44]\ttraining's auc: 0.882789\n",
      "[45]\ttraining's auc: 0.88358\n",
      "[46]\ttraining's auc: 0.884201\n",
      "[47]\ttraining's auc: 0.884963\n",
      "[48]\ttraining's auc: 0.885515\n",
      "[49]\ttraining's auc: 0.885309\n",
      "[50]\ttraining's auc: 0.885088\n",
      "[51]\ttraining's auc: 0.885389\n",
      "[52]\ttraining's auc: 0.88703\n",
      "[53]\ttraining's auc: 0.886901\n",
      "[54]\ttraining's auc: 0.887599\n",
      "[55]\ttraining's auc: 0.888307\n",
      "[56]\ttraining's auc: 0.888064\n",
      "[57]\ttraining's auc: 0.88866\n",
      "[58]\ttraining's auc: 0.88914\n",
      "[59]\ttraining's auc: 0.889184\n",
      "[60]\ttraining's auc: 0.8898\n",
      "[61]\ttraining's auc: 0.890163\n",
      "[62]\ttraining's auc: 0.890451\n",
      "[63]\ttraining's auc: 0.891367\n",
      "[64]\ttraining's auc: 0.891709\n",
      "[65]\ttraining's auc: 0.891393\n",
      "[66]\ttraining's auc: 0.892436\n",
      "[67]\ttraining's auc: 0.893037\n",
      "[68]\ttraining's auc: 0.89381\n",
      "[69]\ttraining's auc: 0.893576\n",
      "[70]\ttraining's auc: 0.893394\n",
      "[71]\ttraining's auc: 0.893498\n",
      "[72]\ttraining's auc: 0.893981\n",
      "[73]\ttraining's auc: 0.894807\n",
      "[74]\ttraining's auc: 0.894655\n",
      "[75]\ttraining's auc: 0.89528\n",
      "[76]\ttraining's auc: 0.895343\n",
      "[77]\ttraining's auc: 0.895201\n",
      "[78]\ttraining's auc: 0.895617\n",
      "[79]\ttraining's auc: 0.896335\n",
      "[80]\ttraining's auc: 0.896552\n",
      "[81]\ttraining's auc: 0.896495\n",
      "[82]\ttraining's auc: 0.896978\n",
      "[83]\ttraining's auc: 0.896794\n",
      "[84]\ttraining's auc: 0.896628\n",
      "[85]\ttraining's auc: 0.896656\n",
      "[86]\ttraining's auc: 0.897346\n",
      "[87]\ttraining's auc: 0.898054\n",
      "[88]\ttraining's auc: 0.897891\n",
      "[89]\ttraining's auc: 0.897917\n",
      "[90]\ttraining's auc: 0.897658\n",
      "[91]\ttraining's auc: 0.898007\n",
      "[92]\ttraining's auc: 0.898365\n",
      "[93]\ttraining's auc: 0.898949\n",
      "[94]\ttraining's auc: 0.898692\n",
      "[95]\ttraining's auc: 0.898597\n",
      "[96]\ttraining's auc: 0.898377\n",
      "[97]\ttraining's auc: 0.898689\n",
      "[98]\ttraining's auc: 0.898759\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's auc: 0.898949\n",
      "[1]\ttraining's auc: 0.793411\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.805916\n",
      "[3]\ttraining's auc: 0.81413\n",
      "[4]\ttraining's auc: 0.819099\n",
      "[5]\ttraining's auc: 0.826433\n",
      "[6]\ttraining's auc: 0.831262\n",
      "[7]\ttraining's auc: 0.83605\n",
      "[8]\ttraining's auc: 0.83645\n",
      "[9]\ttraining's auc: 0.839886\n",
      "[10]\ttraining's auc: 0.844695\n",
      "[11]\ttraining's auc: 0.848521\n",
      "[12]\ttraining's auc: 0.848012\n",
      "[13]\ttraining's auc: 0.850743\n",
      "[14]\ttraining's auc: 0.852998\n",
      "[15]\ttraining's auc: 0.855428\n",
      "[16]\ttraining's auc: 0.857305\n",
      "[17]\ttraining's auc: 0.859112\n",
      "[18]\ttraining's auc: 0.86261\n",
      "[19]\ttraining's auc: 0.864494\n",
      "[20]\ttraining's auc: 0.867864\n",
      "[21]\ttraining's auc: 0.86761\n",
      "[22]\ttraining's auc: 0.870281\n",
      "[23]\ttraining's auc: 0.8733\n",
      "[24]\ttraining's auc: 0.874906\n",
      "[25]\ttraining's auc: 0.877254\n",
      "[26]\ttraining's auc: 0.879122\n",
      "[27]\ttraining's auc: 0.880725\n",
      "[28]\ttraining's auc: 0.880476\n",
      "[29]\ttraining's auc: 0.882123\n",
      "[30]\ttraining's auc: 0.883871\n",
      "[31]\ttraining's auc: 0.884594\n",
      "[32]\ttraining's auc: 0.886053\n",
      "[33]\ttraining's auc: 0.888136\n",
      "[34]\ttraining's auc: 0.889648\n",
      "[35]\ttraining's auc: 0.889262\n",
      "[36]\ttraining's auc: 0.889319\n",
      "[37]\ttraining's auc: 0.891215\n",
      "[38]\ttraining's auc: 0.893215\n",
      "[39]\ttraining's auc: 0.895126\n",
      "[40]\ttraining's auc: 0.896746\n",
      "[41]\ttraining's auc: 0.896619\n",
      "[42]\ttraining's auc: 0.898104\n",
      "[43]\ttraining's auc: 0.897568\n",
      "[44]\ttraining's auc: 0.899369\n",
      "[45]\ttraining's auc: 0.900958\n",
      "[46]\ttraining's auc: 0.901949\n",
      "[47]\ttraining's auc: 0.903642\n",
      "[48]\ttraining's auc: 0.904949\n",
      "[49]\ttraining's auc: 0.904716\n",
      "[50]\ttraining's auc: 0.90446\n",
      "[51]\ttraining's auc: 0.906109\n",
      "[52]\ttraining's auc: 0.906918\n",
      "[53]\ttraining's auc: 0.906789\n",
      "[54]\ttraining's auc: 0.908054\n",
      "[55]\ttraining's auc: 0.90948\n",
      "[56]\ttraining's auc: 0.909356\n",
      "[57]\ttraining's auc: 0.910264\n",
      "[58]\ttraining's auc: 0.911037\n",
      "[59]\ttraining's auc: 0.911316\n",
      "[60]\ttraining's auc: 0.912164\n",
      "[61]\ttraining's auc: 0.912837\n",
      "[62]\ttraining's auc: 0.913028\n",
      "[63]\ttraining's auc: 0.913994\n",
      "[64]\ttraining's auc: 0.914601\n",
      "[65]\ttraining's auc: 0.913994\n",
      "[66]\ttraining's auc: 0.915642\n",
      "[67]\ttraining's auc: 0.916477\n",
      "[68]\ttraining's auc: 0.91787\n",
      "[69]\ttraining's auc: 0.91764\n",
      "[70]\ttraining's auc: 0.917362\n",
      "[71]\ttraining's auc: 0.91758\n",
      "[72]\ttraining's auc: 0.918394\n",
      "[73]\ttraining's auc: 0.919567\n",
      "[74]\ttraining's auc: 0.919109\n",
      "[75]\ttraining's auc: 0.91984\n",
      "[76]\ttraining's auc: 0.920104\n",
      "[77]\ttraining's auc: 0.919875\n",
      "[78]\ttraining's auc: 0.920584\n",
      "[79]\ttraining's auc: 0.921681\n",
      "[80]\ttraining's auc: 0.922304\n",
      "[81]\ttraining's auc: 0.92223\n",
      "[82]\ttraining's auc: 0.922637\n",
      "[83]\ttraining's auc: 0.922345\n",
      "[84]\ttraining's auc: 0.922008\n",
      "[85]\ttraining's auc: 0.921968\n",
      "[86]\ttraining's auc: 0.922661\n",
      "[87]\ttraining's auc: 0.923131\n",
      "[88]\ttraining's auc: 0.922877\n",
      "[89]\ttraining's auc: 0.923072\n",
      "[90]\ttraining's auc: 0.922655\n",
      "[91]\ttraining's auc: 0.923296\n",
      "[92]\ttraining's auc: 0.923569\n",
      "[93]\ttraining's auc: 0.924421\n",
      "[94]\ttraining's auc: 0.924111\n",
      "[95]\ttraining's auc: 0.924082\n",
      "[96]\ttraining's auc: 0.923794\n",
      "[97]\ttraining's auc: 0.924742\n",
      "[98]\ttraining's auc: 0.924736\n",
      "[99]\ttraining's auc: 0.925266\n",
      "[100]\ttraining's auc: 0.926719\n",
      "[101]\ttraining's auc: 0.927048\n",
      "[102]\ttraining's auc: 0.926717\n",
      "[103]\ttraining's auc: 0.926577\n",
      "[104]\ttraining's auc: 0.926954\n",
      "[105]\ttraining's auc: 0.927313\n",
      "[106]\ttraining's auc: 0.927173\n",
      "[107]\ttraining's auc: 0.927205\n",
      "[108]\ttraining's auc: 0.928409\n",
      "[109]\ttraining's auc: 0.92835\n",
      "[110]\ttraining's auc: 0.928023\n",
      "[111]\ttraining's auc: 0.928475\n",
      "[112]\ttraining's auc: 0.928557\n",
      "[113]\ttraining's auc: 0.930108\n",
      "[114]\ttraining's auc: 0.93103\n",
      "[115]\ttraining's auc: 0.932698\n",
      "[116]\ttraining's auc: 0.933703\n",
      "[117]\ttraining's auc: 0.933693\n",
      "[118]\ttraining's auc: 0.934454\n",
      "[119]\ttraining's auc: 0.934408\n",
      "[120]\ttraining's auc: 0.93418\n",
      "[121]\ttraining's auc: 0.933995\n",
      "[122]\ttraining's auc: 0.933982\n",
      "[123]\ttraining's auc: 0.934546\n",
      "[124]\ttraining's auc: 0.935074\n",
      "[125]\ttraining's auc: 0.935324\n",
      "[126]\ttraining's auc: 0.935067\n",
      "[127]\ttraining's auc: 0.93578\n",
      "[128]\ttraining's auc: 0.935856\n",
      "[129]\ttraining's auc: 0.936455\n",
      "[130]\ttraining's auc: 0.937455\n",
      "[131]\ttraining's auc: 0.937356\n",
      "[132]\ttraining's auc: 0.938195\n",
      "[133]\ttraining's auc: 0.939008\n",
      "[134]\ttraining's auc: 0.939095\n",
      "[135]\ttraining's auc: 0.939887\n",
      "[136]\ttraining's auc: 0.940127\n",
      "[137]\ttraining's auc: 0.940164\n",
      "[138]\ttraining's auc: 0.940475\n",
      "[139]\ttraining's auc: 0.940996\n",
      "[140]\ttraining's auc: 0.940934\n",
      "[141]\ttraining's auc: 0.94071\n",
      "[142]\ttraining's auc: 0.940576\n",
      "[143]\ttraining's auc: 0.941862\n",
      "[144]\ttraining's auc: 0.941685\n",
      "[145]\ttraining's auc: 0.942352\n",
      "[146]\ttraining's auc: 0.942263\n",
      "[147]\ttraining's auc: 0.941999\n",
      "[148]\ttraining's auc: 0.942022\n",
      "[149]\ttraining's auc: 0.942301\n",
      "[150]\ttraining's auc: 0.942863\n",
      "[151]\ttraining's auc: 0.942909\n",
      "[152]\ttraining's auc: 0.943061\n",
      "[153]\ttraining's auc: 0.943569\n",
      "[154]\ttraining's auc: 0.943383\n",
      "[155]\ttraining's auc: 0.943765\n",
      "[156]\ttraining's auc: 0.943473\n",
      "[157]\ttraining's auc: 0.94328\n",
      "[158]\ttraining's auc: 0.943048\n",
      "[159]\ttraining's auc: 0.942844\n",
      "[160]\ttraining's auc: 0.942569\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's auc: 0.943765\n",
      "[1]\ttraining's auc: 0.779777\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.803736\n",
      "[3]\ttraining's auc: 0.815504\n",
      "[4]\ttraining's auc: 0.824715\n",
      "[5]\ttraining's auc: 0.833832\n",
      "[6]\ttraining's auc: 0.839112\n",
      "[7]\ttraining's auc: 0.844746\n",
      "[8]\ttraining's auc: 0.845693\n",
      "[9]\ttraining's auc: 0.84937\n",
      "[10]\ttraining's auc: 0.852709\n",
      "[11]\ttraining's auc: 0.854976\n",
      "[12]\ttraining's auc: 0.854868\n",
      "[13]\ttraining's auc: 0.856655\n",
      "[14]\ttraining's auc: 0.858658\n",
      "[15]\ttraining's auc: 0.860879\n",
      "[16]\ttraining's auc: 0.862626\n",
      "[17]\ttraining's auc: 0.864319\n",
      "[18]\ttraining's auc: 0.867428\n",
      "[19]\ttraining's auc: 0.868689\n",
      "[20]\ttraining's auc: 0.870876\n",
      "[21]\ttraining's auc: 0.870954\n",
      "[22]\ttraining's auc: 0.87211\n",
      "[23]\ttraining's auc: 0.873618\n",
      "[24]\ttraining's auc: 0.874856\n",
      "[25]\ttraining's auc: 0.876322\n",
      "[26]\ttraining's auc: 0.877447\n",
      "[27]\ttraining's auc: 0.87839\n",
      "[28]\ttraining's auc: 0.878284\n",
      "[29]\ttraining's auc: 0.879264\n",
      "[30]\ttraining's auc: 0.880271\n",
      "[31]\ttraining's auc: 0.880459\n",
      "[32]\ttraining's auc: 0.882084\n",
      "[33]\ttraining's auc: 0.882898\n",
      "[34]\ttraining's auc: 0.883779\n",
      "[35]\ttraining's auc: 0.883497\n",
      "[36]\ttraining's auc: 0.883503\n",
      "[37]\ttraining's auc: 0.884197\n",
      "[38]\ttraining's auc: 0.884972\n",
      "[39]\ttraining's auc: 0.886587\n",
      "[40]\ttraining's auc: 0.887491\n",
      "[41]\ttraining's auc: 0.887343\n",
      "[42]\ttraining's auc: 0.888129\n",
      "[43]\ttraining's auc: 0.887843\n",
      "[44]\ttraining's auc: 0.888867\n",
      "[45]\ttraining's auc: 0.889623\n",
      "[46]\ttraining's auc: 0.890314\n",
      "[47]\ttraining's auc: 0.891344\n",
      "[48]\ttraining's auc: 0.891841\n",
      "[49]\ttraining's auc: 0.891649\n",
      "[50]\ttraining's auc: 0.891394\n",
      "[51]\ttraining's auc: 0.891923\n",
      "[52]\ttraining's auc: 0.892307\n",
      "[53]\ttraining's auc: 0.892202\n",
      "[54]\ttraining's auc: 0.892782\n",
      "[55]\ttraining's auc: 0.893539\n",
      "[56]\ttraining's auc: 0.893399\n",
      "[57]\ttraining's auc: 0.894077\n",
      "[58]\ttraining's auc: 0.894602\n",
      "[59]\ttraining's auc: 0.894678\n",
      "[60]\ttraining's auc: 0.895478\n",
      "[61]\ttraining's auc: 0.895879\n",
      "[62]\ttraining's auc: 0.89699\n",
      "[63]\ttraining's auc: 0.897759\n",
      "[64]\ttraining's auc: 0.898008\n",
      "[65]\ttraining's auc: 0.897821\n",
      "[66]\ttraining's auc: 0.89873\n",
      "[67]\ttraining's auc: 0.899311\n",
      "[68]\ttraining's auc: 0.899919\n",
      "[69]\ttraining's auc: 0.899837\n",
      "[70]\ttraining's auc: 0.899666\n",
      "[71]\ttraining's auc: 0.899642\n",
      "[72]\ttraining's auc: 0.900076\n",
      "[73]\ttraining's auc: 0.900583\n",
      "[74]\ttraining's auc: 0.900391\n",
      "[75]\ttraining's auc: 0.901048\n",
      "[76]\ttraining's auc: 0.901113\n",
      "[77]\ttraining's auc: 0.90105\n",
      "[78]\ttraining's auc: 0.901391\n",
      "[79]\ttraining's auc: 0.901791\n",
      "[80]\ttraining's auc: 0.902305\n",
      "[81]\ttraining's auc: 0.902226\n",
      "[82]\ttraining's auc: 0.902591\n",
      "[83]\ttraining's auc: 0.902486\n",
      "[84]\ttraining's auc: 0.902398\n",
      "[85]\ttraining's auc: 0.902342\n",
      "[86]\ttraining's auc: 0.903429\n",
      "[87]\ttraining's auc: 0.903869\n",
      "[88]\ttraining's auc: 0.903734\n",
      "[89]\ttraining's auc: 0.903827\n",
      "[90]\ttraining's auc: 0.903604\n",
      "[91]\ttraining's auc: 0.903915\n",
      "[92]\ttraining's auc: 0.904139\n",
      "[93]\ttraining's auc: 0.904701\n",
      "[94]\ttraining's auc: 0.90455\n",
      "[95]\ttraining's auc: 0.904487\n",
      "[96]\ttraining's auc: 0.904316\n",
      "[97]\ttraining's auc: 0.904706\n",
      "[98]\ttraining's auc: 0.904694\n",
      "[99]\ttraining's auc: 0.905056\n",
      "[100]\ttraining's auc: 0.905862\n",
      "[101]\ttraining's auc: 0.906018\n",
      "[102]\ttraining's auc: 0.905801\n",
      "[103]\ttraining's auc: 0.905731\n",
      "[104]\ttraining's auc: 0.90617\n",
      "[105]\ttraining's auc: 0.906384\n",
      "[106]\ttraining's auc: 0.906317\n",
      "[107]\ttraining's auc: 0.906215\n",
      "[108]\ttraining's auc: 0.906765\n",
      "[109]\ttraining's auc: 0.906729\n",
      "[110]\ttraining's auc: 0.906578\n",
      "[111]\ttraining's auc: 0.906633\n",
      "[112]\ttraining's auc: 0.907034\n",
      "[113]\ttraining's auc: 0.9077\n",
      "[114]\ttraining's auc: 0.908185\n",
      "[115]\ttraining's auc: 0.908755\n",
      "[116]\ttraining's auc: 0.909132\n",
      "[117]\ttraining's auc: 0.909135\n",
      "[118]\ttraining's auc: 0.909461\n",
      "[119]\ttraining's auc: 0.909474\n",
      "[120]\ttraining's auc: 0.909373\n",
      "[121]\ttraining's auc: 0.909176\n",
      "[122]\ttraining's auc: 0.909115\n",
      "[123]\ttraining's auc: 0.909598\n",
      "[124]\ttraining's auc: 0.909953\n",
      "[125]\ttraining's auc: 0.910038\n",
      "[126]\ttraining's auc: 0.909881\n",
      "[127]\ttraining's auc: 0.910259\n",
      "[128]\ttraining's auc: 0.910285\n",
      "[129]\ttraining's auc: 0.910472\n",
      "[130]\ttraining's auc: 0.910888\n",
      "[131]\ttraining's auc: 0.91078\n",
      "[132]\ttraining's auc: 0.911047\n",
      "[133]\ttraining's auc: 0.911557\n",
      "[134]\ttraining's auc: 0.911582\n",
      "[135]\ttraining's auc: 0.911878\n",
      "[136]\ttraining's auc: 0.912013\n",
      "[137]\ttraining's auc: 0.912027\n",
      "[138]\ttraining's auc: 0.912539\n",
      "[139]\ttraining's auc: 0.912995\n",
      "[140]\ttraining's auc: 0.912934\n",
      "[141]\ttraining's auc: 0.912827\n",
      "[142]\ttraining's auc: 0.912807\n",
      "[143]\ttraining's auc: 0.913304\n",
      "[144]\ttraining's auc: 0.913219\n",
      "[145]\ttraining's auc: 0.913465\n",
      "[146]\ttraining's auc: 0.913434\n",
      "[147]\ttraining's auc: 0.913256\n",
      "[148]\ttraining's auc: 0.913226\n",
      "[149]\ttraining's auc: 0.91324\n",
      "[150]\ttraining's auc: 0.913633\n",
      "[151]\ttraining's auc: 0.913656\n",
      "[152]\ttraining's auc: 0.91371\n",
      "[153]\ttraining's auc: 0.913819\n",
      "[154]\ttraining's auc: 0.91371\n",
      "[155]\ttraining's auc: 0.913931\n",
      "[156]\ttraining's auc: 0.913763\n",
      "[157]\ttraining's auc: 0.91369\n",
      "[158]\ttraining's auc: 0.913602\n",
      "[159]\ttraining's auc: 0.913511\n",
      "[160]\ttraining's auc: 0.913365\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's auc: 0.913931\n",
      "[1]\ttraining's auc: 0.779476\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.799302\n",
      "[3]\ttraining's auc: 0.80735\n",
      "[4]\ttraining's auc: 0.815549\n",
      "[5]\ttraining's auc: 0.825018\n",
      "[6]\ttraining's auc: 0.830895\n",
      "[7]\ttraining's auc: 0.835411\n",
      "[8]\ttraining's auc: 0.836009\n",
      "[9]\ttraining's auc: 0.839648\n",
      "[10]\ttraining's auc: 0.845034\n",
      "[11]\ttraining's auc: 0.847822\n",
      "[12]\ttraining's auc: 0.847945\n",
      "[13]\ttraining's auc: 0.85025\n",
      "[14]\ttraining's auc: 0.852306\n",
      "[15]\ttraining's auc: 0.854985\n",
      "[16]\ttraining's auc: 0.857448\n",
      "[17]\ttraining's auc: 0.85953\n",
      "[18]\ttraining's auc: 0.86305\n",
      "[19]\ttraining's auc: 0.865907\n",
      "[20]\ttraining's auc: 0.869291\n",
      "[21]\ttraining's auc: 0.869507\n",
      "[22]\ttraining's auc: 0.871189\n",
      "[23]\ttraining's auc: 0.875125\n",
      "[24]\ttraining's auc: 0.877309\n",
      "[25]\ttraining's auc: 0.879433\n",
      "[26]\ttraining's auc: 0.881075\n",
      "[27]\ttraining's auc: 0.88353\n",
      "[28]\ttraining's auc: 0.883215\n",
      "[29]\ttraining's auc: 0.885234\n",
      "[30]\ttraining's auc: 0.887036\n",
      "[31]\ttraining's auc: 0.887423\n",
      "[32]\ttraining's auc: 0.888775\n",
      "[33]\ttraining's auc: 0.890775\n",
      "[34]\ttraining's auc: 0.892411\n",
      "[35]\ttraining's auc: 0.892061\n",
      "[36]\ttraining's auc: 0.892007\n",
      "[37]\ttraining's auc: 0.893284\n",
      "[38]\ttraining's auc: 0.894736\n",
      "[39]\ttraining's auc: 0.896728\n",
      "[40]\ttraining's auc: 0.898564\n",
      "[41]\ttraining's auc: 0.898546\n",
      "[42]\ttraining's auc: 0.900204\n",
      "[43]\ttraining's auc: 0.899707\n",
      "[44]\ttraining's auc: 0.901032\n",
      "[45]\ttraining's auc: 0.902406\n",
      "[46]\ttraining's auc: 0.903201\n",
      "[47]\ttraining's auc: 0.904543\n",
      "[48]\ttraining's auc: 0.90565\n",
      "[49]\ttraining's auc: 0.905317\n",
      "[50]\ttraining's auc: 0.904921\n",
      "[51]\ttraining's auc: 0.906302\n",
      "[52]\ttraining's auc: 0.907222\n",
      "[53]\ttraining's auc: 0.907057\n",
      "[54]\ttraining's auc: 0.908556\n",
      "[55]\ttraining's auc: 0.909814\n",
      "[56]\ttraining's auc: 0.90972\n",
      "[57]\ttraining's auc: 0.910749\n",
      "[58]\ttraining's auc: 0.911447\n",
      "[59]\ttraining's auc: 0.911755\n",
      "[60]\ttraining's auc: 0.913006\n",
      "[61]\ttraining's auc: 0.913604\n",
      "[62]\ttraining's auc: 0.914249\n",
      "[63]\ttraining's auc: 0.915234\n",
      "[64]\ttraining's auc: 0.915688\n",
      "[65]\ttraining's auc: 0.915276\n",
      "[66]\ttraining's auc: 0.917299\n",
      "[67]\ttraining's auc: 0.91818\n",
      "[68]\ttraining's auc: 0.919244\n",
      "[69]\ttraining's auc: 0.91895\n",
      "[70]\ttraining's auc: 0.918703\n",
      "[71]\ttraining's auc: 0.91907\n",
      "[72]\ttraining's auc: 0.919908\n",
      "[73]\ttraining's auc: 0.920894\n",
      "[74]\ttraining's auc: 0.920423\n",
      "[75]\ttraining's auc: 0.92151\n",
      "[76]\ttraining's auc: 0.921502\n",
      "[77]\ttraining's auc: 0.921284\n",
      "[78]\ttraining's auc: 0.922026\n",
      "[79]\ttraining's auc: 0.922735\n",
      "[80]\ttraining's auc: 0.923462\n",
      "[81]\ttraining's auc: 0.923387\n",
      "[82]\ttraining's auc: 0.924021\n",
      "[83]\ttraining's auc: 0.923881\n",
      "[84]\ttraining's auc: 0.923508\n",
      "[85]\ttraining's auc: 0.923553\n",
      "[86]\ttraining's auc: 0.924095\n",
      "[87]\ttraining's auc: 0.925111\n",
      "[88]\ttraining's auc: 0.924907\n",
      "[89]\ttraining's auc: 0.925035\n",
      "[90]\ttraining's auc: 0.924693\n",
      "[91]\ttraining's auc: 0.925261\n",
      "[92]\ttraining's auc: 0.92592\n",
      "[93]\ttraining's auc: 0.926689\n",
      "[94]\ttraining's auc: 0.926373\n",
      "[95]\ttraining's auc: 0.926257\n",
      "[96]\ttraining's auc: 0.925894\n",
      "[97]\ttraining's auc: 0.926303\n",
      "[98]\ttraining's auc: 0.926391\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's auc: 0.926689\n",
      "[1]\ttraining's auc: 0.855105\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.878593\n",
      "[3]\ttraining's auc: 0.891242\n",
      "[4]\ttraining's auc: 0.90249\n",
      "[5]\ttraining's auc: 0.913923\n",
      "[6]\ttraining's auc: 0.920734\n",
      "[7]\ttraining's auc: 0.928168\n",
      "[8]\ttraining's auc: 0.930158\n",
      "[9]\ttraining's auc: 0.936386\n",
      "[10]\ttraining's auc: 0.941764\n",
      "[11]\ttraining's auc: 0.948884\n",
      "[12]\ttraining's auc: 0.947915\n",
      "[13]\ttraining's auc: 0.951017\n",
      "[14]\ttraining's auc: 0.955343\n",
      "[15]\ttraining's auc: 0.960983\n",
      "[16]\ttraining's auc: 0.964303\n",
      "[17]\ttraining's auc: 0.966696\n",
      "[18]\ttraining's auc: 0.970966\n",
      "[19]\ttraining's auc: 0.973614\n",
      "[20]\ttraining's auc: 0.97743\n",
      "[21]\ttraining's auc: 0.977392\n",
      "[22]\ttraining's auc: 0.979716\n",
      "[23]\ttraining's auc: 0.981979\n",
      "[24]\ttraining's auc: 0.984099\n",
      "[25]\ttraining's auc: 0.985834\n",
      "[26]\ttraining's auc: 0.987453\n",
      "[27]\ttraining's auc: 0.988812\n",
      "[28]\ttraining's auc: 0.988647\n",
      "[29]\ttraining's auc: 0.989458\n",
      "[30]\ttraining's auc: 0.990352\n",
      "[31]\ttraining's auc: 0.990843\n",
      "[32]\ttraining's auc: 0.991417\n",
      "[33]\ttraining's auc: 0.991959\n",
      "[34]\ttraining's auc: 0.992407\n",
      "[35]\ttraining's auc: 0.992137\n",
      "[36]\ttraining's auc: 0.992166\n",
      "[37]\ttraining's auc: 0.992862\n",
      "[38]\ttraining's auc: 0.993392\n",
      "[39]\ttraining's auc: 0.994207\n",
      "[40]\ttraining's auc: 0.994427\n",
      "[41]\ttraining's auc: 0.994402\n",
      "[42]\ttraining's auc: 0.994787\n",
      "[43]\ttraining's auc: 0.99451\n",
      "[44]\ttraining's auc: 0.995416\n",
      "[45]\ttraining's auc: 0.99603\n",
      "[46]\ttraining's auc: 0.996233\n",
      "[47]\ttraining's auc: 0.996415\n",
      "[48]\ttraining's auc: 0.996501\n",
      "[49]\ttraining's auc: 0.996466\n",
      "[50]\ttraining's auc: 0.996408\n",
      "[51]\ttraining's auc: 0.996699\n",
      "[52]\ttraining's auc: 0.996929\n",
      "[53]\ttraining's auc: 0.996986\n",
      "[54]\ttraining's auc: 0.997182\n",
      "[55]\ttraining's auc: 0.99725\n",
      "[56]\ttraining's auc: 0.997194\n",
      "[57]\ttraining's auc: 0.997513\n",
      "[58]\ttraining's auc: 0.99767\n",
      "[59]\ttraining's auc: 0.997705\n",
      "[60]\ttraining's auc: 0.997738\n",
      "[61]\ttraining's auc: 0.997788\n",
      "[62]\ttraining's auc: 0.997873\n",
      "[63]\ttraining's auc: 0.997952\n",
      "[64]\ttraining's auc: 0.997977\n",
      "[65]\ttraining's auc: 0.997911\n",
      "[66]\ttraining's auc: 0.997907\n",
      "[67]\ttraining's auc: 0.997987\n",
      "[68]\ttraining's auc: 0.998224\n",
      "[69]\ttraining's auc: 0.998205\n",
      "[70]\ttraining's auc: 0.998199\n",
      "[71]\ttraining's auc: 0.998261\n",
      "[72]\ttraining's auc: 0.998303\n",
      "[73]\ttraining's auc: 0.998408\n",
      "[74]\ttraining's auc: 0.998364\n",
      "[75]\ttraining's auc: 0.998543\n",
      "[76]\ttraining's auc: 0.998548\n",
      "[77]\ttraining's auc: 0.998548\n",
      "[78]\ttraining's auc: 0.998603\n",
      "[79]\ttraining's auc: 0.998529\n",
      "[80]\ttraining's auc: 0.998626\n",
      "[81]\ttraining's auc: 0.998632\n",
      "[82]\ttraining's auc: 0.998595\n",
      "[83]\ttraining's auc: 0.998567\n",
      "[84]\ttraining's auc: 0.998518\n",
      "[85]\ttraining's auc: 0.998506\n",
      "[86]\ttraining's auc: 0.998538\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's auc: 0.998632\n",
      "[1]\ttraining's auc: 0.879313\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.901505\n",
      "[3]\ttraining's auc: 0.917262\n",
      "[4]\ttraining's auc: 0.926316\n",
      "[5]\ttraining's auc: 0.932169\n",
      "[6]\ttraining's auc: 0.936702\n",
      "[7]\ttraining's auc: 0.944017\n",
      "[8]\ttraining's auc: 0.944134\n",
      "[9]\ttraining's auc: 0.950958\n",
      "[10]\ttraining's auc: 0.958803\n",
      "[11]\ttraining's auc: 0.966813\n",
      "[12]\ttraining's auc: 0.965666\n",
      "[13]\ttraining's auc: 0.970592\n",
      "[14]\ttraining's auc: 0.97544\n",
      "[15]\ttraining's auc: 0.979425\n",
      "[16]\ttraining's auc: 0.981802\n",
      "[17]\ttraining's auc: 0.98464\n",
      "[18]\ttraining's auc: 0.986435\n",
      "[19]\ttraining's auc: 0.98954\n",
      "[20]\ttraining's auc: 0.991244\n",
      "[21]\ttraining's auc: 0.991934\n",
      "[22]\ttraining's auc: 0.993409\n",
      "[23]\ttraining's auc: 0.994824\n",
      "[24]\ttraining's auc: 0.996213\n",
      "[25]\ttraining's auc: 0.997602\n",
      "[26]\ttraining's auc: 0.998016\n",
      "[27]\ttraining's auc: 0.998016\n",
      "[28]\ttraining's auc: 0.998033\n",
      "[29]\ttraining's auc: 0.998007\n",
      "[30]\ttraining's auc: 0.998482\n",
      "[31]\ttraining's auc: 0.998473\n",
      "[32]\ttraining's auc: 0.998939\n",
      "[33]\ttraining's auc: 0.99906\n",
      "[34]\ttraining's auc: 0.99918\n",
      "[35]\ttraining's auc: 0.999224\n",
      "[36]\ttraining's auc: 0.999206\n",
      "[37]\ttraining's auc: 0.999439\n",
      "[38]\ttraining's auc: 0.999457\n",
      "[39]\ttraining's auc: 0.999702\n",
      "[40]\ttraining's auc: 0.999737\n",
      "[41]\ttraining's auc: 0.999746\n",
      "[42]\ttraining's auc: 0.999651\n",
      "[43]\ttraining's auc: 0.999668\n",
      "[44]\ttraining's auc: 0.999711\n",
      "[45]\ttraining's auc: 0.999702\n",
      "[46]\ttraining's auc: 0.999711\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.999746\n",
      "[1]\ttraining's auc: 0.708494\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's auc: 0.795367\n",
      "[3]\ttraining's auc: 0.823037\n",
      "[4]\ttraining's auc: 0.85296\n",
      "[5]\ttraining's auc: 0.847169\n",
      "[6]\ttraining's auc: 0.856821\n",
      "[7]\ttraining's auc: 0.856821\n",
      "[8]\ttraining's auc: 0.851351\n",
      "[9]\ttraining's auc: 0.865187\n",
      "[10]\ttraining's auc: 0.872587\n",
      "[11]\ttraining's auc: 0.873552\n",
      "[12]\ttraining's auc: 0.870978\n",
      "[13]\ttraining's auc: 0.881918\n",
      "[14]\ttraining's auc: 0.886422\n",
      "[15]\ttraining's auc: 0.893501\n",
      "[16]\ttraining's auc: 0.89897\n",
      "[17]\ttraining's auc: 0.89704\n",
      "[18]\ttraining's auc: 0.903475\n",
      "[19]\ttraining's auc: 0.904118\n",
      "[20]\ttraining's auc: 0.908623\n",
      "[21]\ttraining's auc: 0.90991\n",
      "[22]\ttraining's auc: 0.913127\n",
      "[23]\ttraining's auc: 0.913127\n",
      "[24]\ttraining's auc: 0.915058\n",
      "[25]\ttraining's auc: 0.915058\n",
      "[26]\ttraining's auc: 0.92278\n",
      "[27]\ttraining's auc: 0.925997\n",
      "[28]\ttraining's auc: 0.926641\n",
      "[29]\ttraining's auc: 0.927284\n",
      "[30]\ttraining's auc: 0.933719\n",
      "[31]\ttraining's auc: 0.936615\n",
      "[32]\ttraining's auc: 0.939833\n",
      "[33]\ttraining's auc: 0.941763\n",
      "[34]\ttraining's auc: 0.943694\n",
      "[35]\ttraining's auc: 0.946911\n",
      "[36]\ttraining's auc: 0.947555\n",
      "[37]\ttraining's auc: 0.947555\n",
      "[38]\ttraining's auc: 0.950129\n",
      "[39]\ttraining's auc: 0.944337\n",
      "[40]\ttraining's auc: 0.945624\n",
      "[41]\ttraining's auc: 0.946911\n",
      "[42]\ttraining's auc: 0.949485\n",
      "[43]\ttraining's auc: 0.948198\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.950129\n"
     ]
    }
   ],
   "source": [
    "language_models = {}\n",
    "for lang in model_df['language'].unique():\n",
    "    language_models[lang] = lgbm_train(df, 'language', lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulating final predictions and exporting to csv for submission\n",
    "beware, very slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "males = gender_models['male'].predict(test_sub.drop('gender', 1))\n",
    "females = gender_models['female'].predict(test_sub.drop('gender', 1))\n",
    "\n",
    "print('looping…')\n",
    "for i in range(len(test_sub)):\n",
    "\n",
    "    if test_sub.iloc[i]['gender'] == 'male':\n",
    "        results.append(males[i])\n",
    "    else:\n",
    "        results.append(females[i])\n",
    "\n",
    "print('finished looping. Submitting…')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = results\n",
    "submission.to_csv('lgbm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_predictions = {}\n",
    "for key in language_models.keys():\n",
    "    lang_predictions[key] = language_models[key].predict(test_sub.drop('gender', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished looping. Submitting…\n"
     ]
    }
   ],
   "source": [
    "lang_results = []\n",
    "for i in range(len(test_sub)):    \n",
    "    lang_results.append(lang_predictions[test_sub.iloc[i]['language']][i])\n",
    "\n",
    "print('finished looping. Submitting…')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = lang_results\n",
    "submission.to_csv('lgbm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final training and exporting for LightGBM (standard models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_df = lgb.Dataset(df.drop('target', 1), label = df['target'].values)\n",
    "\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'}\n",
    "\n",
    "print('training…')\n",
    "gbm_full = lgb.train(params,\n",
    "                lgb_df,\n",
    "                num_boost_round=100,\n",
    "                valid_sets = lgb_df,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('predicting…')\n",
    "predictions = gbm_full.predict(test_sub)\n",
    "\n",
    "print('exporting…')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = predictions\n",
    "submission.to_csv('lgbm_submission.csv',index=False)\n",
    "\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final training and exporting (for sklearn models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_export(model):\n",
    "    model.fit(df.drop('target', 1), df['target'])\n",
    "    predictions = pd.Series(model.predict(test))\n",
    "    submission = pd.DataFrame({'target':predictions}, index = ids)\n",
    "    submission.to_csv('submission.csv')\n",
    "\n",
    "# train_export(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [0.57, .62, .44, .48, .66, .67, .66, .66]\n",
    "plt.plot(data)\n",
    "plt.plot([0.5, .5, .5, .5, .5, .5, .5, .5], c = 'red')\n",
    "plt.plot([0.74, .74, .74, .74, .74, .74, .74, .74], c = 'lime')\n",
    "plt.title('Our Scores Over Time')\n",
    "plt.xlabel('Submission Number')\n",
    "plt.ylabel('AUC')\n",
    "plt.show()\n",
    "# plt.savefig('auc_graph.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
