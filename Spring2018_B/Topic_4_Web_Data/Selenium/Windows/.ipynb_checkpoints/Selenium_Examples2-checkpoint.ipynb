{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium\n",
    "## Web Browser automation and Scraping\n",
    "\n",
    "Selenium is a Python package that allows you to automate your web browser and to scrape data off web pages.\n",
    "\n",
    "###### Download Link and Instructions: http://selenium-python.readthedocs.io/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Scraping from Cav Daily Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver #pip install selenium first...\n",
    "import time # this is for sleeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing the browser and going to a web page\n",
    "\n",
    "# open instance of browser\n",
    "browser = webdriver.Chrome()#Note: you may need to put the path of your webdriver in the parentheses as a string\n",
    "\n",
    "# go to the web page that we want to scrape from\n",
    "browser.get('https://cavdailyonline.github.io/facultysalarygryphon/')\n",
    "\n",
    "# wait for browser/page to load before doing anything else\n",
    "'''\n",
    "If you don't do this, selenium may get confused while running \n",
    "the next command because whatever object it looks for may not yet be there.\n",
    "So when running a command that will open a new web page it is usually\n",
    "a good idea to sleep for a few seconds.\n",
    "''' \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium allows you to select web page elements in a variety of ways:\n",
    "                                    1. .find_element_by_class_name\n",
    "                                    2. .find_element_by_css_selector\n",
    "                                    3. .find_element_by_id\n",
    "                                    4. .find_element_by_link_text\n",
    "                                    5. .find_element_by_name\n",
    "                                    6. .find_element_by_partial_link_text\n",
    "                                    7. .find_element_by_tag_name\n",
    "                                    8. .find_element_by_xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data Across 428 Pages... All at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page: 10\n",
      "Scraping Page: 20\n",
      "Scraping Page: 30\n",
      "Scraping Page: 40\n",
      "Scraping Page: 50\n",
      "Scraping Page: 60\n",
      "Scraping Page: 70\n",
      "Scraping Page: 80\n",
      "Scraping Page: 90\n",
      "Scraping Page: 100\n",
      "Scraping Page: 110\n",
      "Scraping Page: 120\n",
      "Scraping Page: 130\n",
      "Scraping Page: 140\n",
      "Scraping Page: 150\n",
      "Scraping Page: 160\n",
      "Scraping Page: 170\n",
      "Scraping Page: 180\n",
      "Scraping Page: 190\n",
      "Scraping Page: 200\n",
      "Scraping Page: 210\n",
      "Scraping Page: 220\n",
      "Scraping Page: 230\n",
      "Scraping Page: 240\n",
      "Scraping Page: 250\n",
      "Scraping Page: 260\n",
      "Scraping Page: 270\n",
      "Scraping Page: 280\n",
      "Scraping Page: 290\n",
      "Scraping Page: 300\n",
      "Scraping Page: 310\n",
      "Scraping Page: 320\n",
      "Scraping Page: 330\n",
      "Scraping Page: 340\n",
      "Scraping Page: 350\n",
      "Scraping Page: 360\n",
      "Scraping Page: 370\n",
      "Scraping Page: 380\n",
      "Scraping Page: 390\n",
      "Scraping Page: 400\n",
      "Scraping Page: 410\n",
      "Scraping Page: 420\n",
      "(10675, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Division</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron, Bradley J (Brad)</td>\n",
       "      <td>53560</td>\n",
       "      <td>AS-College of Arts &amp; Sciences</td>\n",
       "      <td>Education and Outreach Manager-EO58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abad-Jorge, Ana R</td>\n",
       "      <td>144900</td>\n",
       "      <td>CP-School of Cont/Prof Studies</td>\n",
       "      <td>Assistant Professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abate, Hiwot Mulugeta</td>\n",
       "      <td>32000</td>\n",
       "      <td>MD-School of Medicine</td>\n",
       "      <td>Lab and Research Technician 1-LAB26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abatzis, Vaia T</td>\n",
       "      <td>100000</td>\n",
       "      <td>MD-School of Medicine</td>\n",
       "      <td>Assistant Professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbas, Tarek A</td>\n",
       "      <td>131000</td>\n",
       "      <td>MD-School of Medicine</td>\n",
       "      <td>Assistant Professor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name  Salary                        Division  \\\n",
       "0  Aaron, Bradley J (Brad)   53560   AS-College of Arts & Sciences   \n",
       "1        Abad-Jorge, Ana R  144900  CP-School of Cont/Prof Studies   \n",
       "2    Abate, Hiwot Mulugeta   32000           MD-School of Medicine   \n",
       "3          Abatzis, Vaia T  100000           MD-School of Medicine   \n",
       "4           Abbas, Tarek A  131000           MD-School of Medicine   \n",
       "\n",
       "                                 Title  \n",
       "0  Education and Outreach Manager-EO58  \n",
       "1                  Assistant Professor  \n",
       "2  Lab and Research Technician 1-LAB26  \n",
       "3                  Assistant Professor  \n",
       "4                  Assistant Professor  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clicks = 1\n",
    "#total clicks = 10,678 entries /25 each page\n",
    "df = pd.DataFrame() #blank df\n",
    "while n_clicks < 429:\n",
    "    html = browser.find_element_by_xpath('//*[@id=\"data-table-container\"]').get_attribute('outerHTML')\n",
    "    table_list = pd.read_html(html)\n",
    "    temp_df = table_list[0]\n",
    "    df = df.append(temp_df, ignore_index = True)\n",
    "    #move to next page\n",
    "    browser.find_element_by_xpath('//*[@id=\"data-table-container_wrapper\"]/div[4]/ul/li[7]/a').click()\n",
    "    time.sleep(0.5)\n",
    "    n_clicks += 1\n",
    "    if (n_clicks % 10) is 0:\n",
    "        print(\"Scraping Page: \" + str(n_clicks))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I need this data frame for class. I'm going to save it as an excel document...\n",
    "df.to_excel('cavdaily2015.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's break that down...<br>\n",
    "Steps:<br>\n",
    "1. Go to website<br>\n",
    "https://cavdailyonline.github.io/facultysalarygryphon/<br>\n",
    "2. Right click -> inspect -> find data of interest by clicking around<br>\n",
    "3. Right click -> copy x_path<br>\n",
    "4. Get outer html<br>\n",
    "5. Read html using pd.read_html()<br>\n",
    "6. Find df object (if it exists)\n",
    "7. Find the xpath for the \"next\" button and tell the browser to click it\n",
    "8. Scrape this new page using the same steps as 3-6\n",
    "9. Manually keep doing this or combine these steps into a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#steps 1-5 code\n",
    "html = browser.find_element_by_xpath('//*[@id=\"data-table-container\"]').get_attribute('outerHTML')\n",
    "pd_html = pd.read_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step 6: find df object\n",
    "print(type(pd_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a list. How long is the list? What type are the list elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"List Length: \" + str(len(pd_html)))\n",
    "print(\"Type of List Element 1: \" + str(type(pd_html[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here's our data frame\n",
    "salary_page1 = pd_html(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the code in the for loop I created earlier to see how we could click a button to move to another page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# close the browser now that we've got the data we need\n",
    "'''\n",
    "just for convenience sake because Selenium opens up a new \n",
    "window of your browser everytime you run it... which can get annoying\n",
    "'''\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Slack Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, let's pick a channel and a message to send to that channel\n",
    "\n",
    "# pick your channel\n",
    "channel = 'bot_world'\n",
    "# write a message\n",
    "message = 'Hi there Slack!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# go to the web page that we want to scrape from\n",
    "browser.get('http://slack.com/signin')\n",
    "\n",
    "# wait for browser/page to load before doing anything else\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOGIN\n",
    "#We'll do this by finding elements in different ways, rather than xpath as we did before...\n",
    "\n",
    "# type the slack team name\n",
    "browser.find_element_by_id(\"domain\").send_keys(\"hackcville\")\n",
    "\n",
    "# press continue button\n",
    "browser.find_element_by_id(\"submit_team_domain\").click()\n",
    "\n",
    "# wait for next page to load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: ct3fb@virginia.edu\n",
      "Password: Whisper\n"
     ]
    }
   ],
   "source": [
    "# supply username and password for slack\n",
    "email = input(\"Email: \")\n",
    "password = input(\"Password: \")\n",
    "\n",
    "# type username\n",
    "browser.find_element_by_id(\"email\").send_keys(email)\n",
    "# type password\n",
    "browser.find_element_by_id(\"password\").send_keys(password)\n",
    "# click sign in button\n",
    "browser.find_element_by_id(\"signin_btn\").click()\n",
    "\n",
    "# wait for the next page to load\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\t\\t\\t\\t\\t\\tannouncements\\n\\t\\t\\t\\t'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# navigate to the channel you want to write in\n",
    "\n",
    "'''\n",
    "This finds the elements with class name = \"overflow_ellipse\" \n",
    "whithin the element with id = \"channels\" and puts them all in a list.\n",
    "'''\n",
    "channels = browser.find_element_by_id('channels').find_elements_by_class_name('overflow_ellipsis')\n",
    "\n",
    "# lets see what the inner HTML elements look like\n",
    "channels[0].get_attribute('innerHTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# that is ugly ^^^\n",
    "# let's clean it up with .strip() to clear the whitespace in the for loop\n",
    "\n",
    "'''\n",
    "this just iterates through the stripped inner HTML of the items \n",
    "in the 'channels' list until it finds the one we want then clicks it\n",
    "'''\n",
    "for i in range(len(channels)):\n",
    "    if (channels[i].get_attribute('innerHTML').strip() == channel):\n",
    "        # click on the 'bot_world' channel\n",
    "        channels[i].click()\n",
    "        \n",
    "        # break out of the for loop\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the element for the text bar\n",
    "text_bar = browser.find_element_by_class_name('ql-editor.ql-blank').find_element_by_css_selector('p')\n",
    "# type your message\n",
    "text_bar.send_keys(message)\n",
    "# press enter\n",
    "text_bar.send_keys(u'\\ue007')\n",
    "\n",
    "#you can repeat this cell with different messages to send multiple messages to the channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if you ever want to write a message to Slack but you're in class and don't want to get called out for not working, just whip out this script and no one will suspect anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge(s)\n",
    "1. Scrape the entire table from http://www.imdb.com/title/tt1490017/ by making Selenium press the \"See full cast >>\" button at the bottom of the table which opens up the full cast list, not just the first 15 members.\n",
    "\n",
    "2. Scrape the full cast list from multiple imdb pages by using the search bar to navigate between the pages.\n",
    "3. Go to a popular news source and scrape the first few pages of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
